------------------------------------------------------------------------------------------------------------------
      name:  training
       log:  /home04/UserID/trainings/stata/logs/training_20130708181809.log
  log type:  text
 opened on:   8 Jul 2013, 18:18:09

. 
. 
. set more off 

. 
. /*
> Change the working directory to `directory'. If you want to run this code on your own computer you will
>         need to create the following subdirectories within the directory you have designated as your working
>         directory:
>         - data
>         - do
>         - tex
>         - logs
> You can do this with the mkdir command:
>         mkdir /home/UserID/trainings/stata/do
>         mkdir /home/UserID/trainings/stata/data
>         mkdir /home/UserID/trainings/stata/tex
>         mkdir /home/UserID/trainings/stata/logs
> */
. 
. 
. 
. /* Open the pre-loaded Stata auto data set and save it in a local directory for future use */
. sysuse auto, clear
(1978 Automobile Data)

. save `directory'data/auto.dta, replace
file data/auto.dta saved

. 
. 
. /* Some practice loading and saving data */
.         /* Load a data set*/
.         use `directory'data/auto.dta, clear
(1978 Automobile Data)

.         
.         /* Load a subset of variables from the same data set */
.         use make price mpg rep78 headroom foreign using `directory'data/auto.dta, clear
(1978 Automobile Data)

.         /* Load only observations for foreign cars from the same data set */
.         use if foreign==1 using `directory'data/auto.dta, clear
(1978 Automobile Data)

.         /* Load only a subset of variables and obsrvations for foreign cars from the same data set */
.         use make price mpg rep78 headroom foreign if foreign==1 using `directory'data/auto.dta, clear
(1978 Automobile Data)

. 
.         /* Save the data set we just loaded */
.         save  `directory'data/auto_subset.dta, replace
file data/auto_subset.dta saved

.         
. 
.         /* Output the data set in memory as a .csv file */
.         outsheet using  `directory'data/auto.csv, comma replace

.         /* Output the data set in memory as an Excel .xlsx file */
.         export excel using "`directory'data/auto.xlsx", firstrow(variables) replace
file data/auto.xlsx saved

.         
.         /* Input data from a .csv file */
.         insheet using  `directory'data/auto.csv, comma clear
(6 vars, 22 obs)

.         /* Input data from a .xlsx file */
.         import excel "`directory'data/auto.xlsx", sheet("Sheet1") firstrow clear

.         
.         
. /* Appending and merging data sets */
. 
.         /* Suppose we have data on labor market status split into two data sets --- Pre-1994 and Post-1994. We 
>                 can combine the two by first loading one, and then appending the other */
.         
.         use `directory'data/basic_labor_force_pre1994.dta, clear

.         gen year = year(dofm(date))

.         tab year

       year |      Freq.     Percent        Cum.
------------+-----------------------------------
       1948 |         12        2.17        2.17
       1949 |         12        2.17        4.35
       1950 |         12        2.17        6.52
       1951 |         12        2.17        8.70
       1952 |         12        2.17       10.87
       1953 |         12        2.17       13.04
       1954 |         12        2.17       15.22
       1955 |         12        2.17       17.39
       1956 |         12        2.17       19.57
       1957 |         12        2.17       21.74
       1958 |         12        2.17       23.91
       1959 |         12        2.17       26.09
       1960 |         12        2.17       28.26
       1961 |         12        2.17       30.43
       1962 |         12        2.17       32.61
       1963 |         12        2.17       34.78
       1964 |         12        2.17       36.96
       1965 |         12        2.17       39.13
       1966 |         12        2.17       41.30
       1967 |         12        2.17       43.48
       1968 |         12        2.17       45.65
       1969 |         12        2.17       47.83
       1970 |         12        2.17       50.00
       1971 |         12        2.17       52.17
       1972 |         12        2.17       54.35
       1973 |         12        2.17       56.52
       1974 |         12        2.17       58.70
       1975 |         12        2.17       60.87
       1976 |         12        2.17       63.04
       1977 |         12        2.17       65.22
       1978 |         12        2.17       67.39
       1979 |         12        2.17       69.57
       1980 |         12        2.17       71.74
       1981 |         12        2.17       73.91
       1982 |         12        2.17       76.09
       1983 |         12        2.17       78.26
       1984 |         12        2.17       80.43
       1985 |         12        2.17       82.61
       1986 |         12        2.17       84.78
       1987 |         12        2.17       86.96
       1988 |         12        2.17       89.13
       1989 |         12        2.17       91.30
       1990 |         12        2.17       93.48
       1991 |         12        2.17       95.65
       1992 |         12        2.17       97.83
       1993 |         12        2.17      100.00
------------+-----------------------------------
      Total |        552      100.00

.         append using `directory'data/basic_labor_force_post1994.dta

.         replace year = year(dofm(date))
(232 real changes made)

.         tab year

       year |      Freq.     Percent        Cum.
------------+-----------------------------------
       1948 |         12        1.53        1.53
       1949 |         12        1.53        3.06
       1950 |         12        1.53        4.59
       1951 |         12        1.53        6.12
       1952 |         12        1.53        7.65
       1953 |         12        1.53        9.18
       1954 |         12        1.53       10.71
       1955 |         12        1.53       12.24
       1956 |         12        1.53       13.78
       1957 |         12        1.53       15.31
       1958 |         12        1.53       16.84
       1959 |         12        1.53       18.37
       1960 |         12        1.53       19.90
       1961 |         12        1.53       21.43
       1962 |         12        1.53       22.96
       1963 |         12        1.53       24.49
       1964 |         12        1.53       26.02
       1965 |         12        1.53       27.55
       1966 |         12        1.53       29.08
       1967 |         12        1.53       30.61
       1968 |         12        1.53       32.14
       1969 |         12        1.53       33.67
       1970 |         12        1.53       35.20
       1971 |         12        1.53       36.73
       1972 |         12        1.53       38.27
       1973 |         12        1.53       39.80
       1974 |         12        1.53       41.33
       1975 |         12        1.53       42.86
       1976 |         12        1.53       44.39
       1977 |         12        1.53       45.92
       1978 |         12        1.53       47.45
       1979 |         12        1.53       48.98
       1980 |         12        1.53       50.51
       1981 |         12        1.53       52.04
       1982 |         12        1.53       53.57
       1983 |         12        1.53       55.10
       1984 |         12        1.53       56.63
       1985 |         12        1.53       58.16
       1986 |         12        1.53       59.69
       1987 |         12        1.53       61.22
       1988 |         12        1.53       62.76
       1989 |         12        1.53       64.29
       1990 |         12        1.53       65.82
       1991 |         12        1.53       67.35
       1992 |         12        1.53       68.88
       1993 |         12        1.53       70.41
       1994 |         12        1.53       71.94
       1995 |         12        1.53       73.47
       1996 |         12        1.53       75.00
       1997 |         12        1.53       76.53
       1998 |         12        1.53       78.06
       1999 |         12        1.53       79.59
       2000 |         12        1.53       81.12
       2001 |         12        1.53       82.65
       2002 |         12        1.53       84.18
       2003 |         12        1.53       85.71
       2004 |         12        1.53       87.24
       2005 |         12        1.53       88.78
       2006 |         12        1.53       90.31
       2007 |         12        1.53       91.84
       2008 |         12        1.53       93.37
       2009 |         12        1.53       94.90
       2010 |         12        1.53       96.43
       2011 |         12        1.53       97.96
       2012 |         12        1.53       99.49
       2013 |          4        0.51      100.00
------------+-----------------------------------
      Total |        784      100.00

. 
.         save `directory'data/basic_labor_force.dta, replace
file data/basic_labor_force.dta saved

. 
.         /* Now, let's add a measure of inflation to our data set. Since this means adding variables to our exist
> ing
>                 observations, rather than adding observations to our existing variables, we need to merge the da
> ta
>                 sets. Since both inflation and labor force status are both measured at monthly intervals, we can
>                 perform a simple 1:1 merge. This means that the same variable, in this case date, uniquely ident
> ifies
>                 observations in both data sets. */
. 
.         /* We can quickly check to be sure that date uniquely identifies the data set in memory, although this i
> sn't
>                 actually necessary because the merge command will check and issue an error if date does not uniq
> uely
>                 identify both data sets */
.         isid date

. 
.         /* Now the actual merge command */
.         merge 1:1 date using `directory'data/cpi.dta

    Result                           # of obs.
    -----------------------------------------
    not matched                            12
        from master                         0  (_merge==1)
        from using                         12  (_merge==2)

    matched                               784  (_merge==3)
    -----------------------------------------

. 
.         /* Let's look at how many of the observations were successfully merged. We do this by tabulating _merge,
>                 a variable created by the merge command. */
.         tab _merge

                 _merge |      Freq.     Percent        Cum.
------------------------+-----------------------------------
         using only (2) |         12        1.51        1.51
            matched (3) |        784       98.49      100.00
------------------------+-----------------------------------
                  Total |        796      100.00

.         /*
>                 _merge          Freq.   Percent Cum.                    
>                 using only (2)  12      1.51    1.51
>                 matched (3)     784     98.49   100.00                  
>                 Total           796     100.00
> 
>         Not all observations were successfully merged. This is the case for many merges, however if not
>                 all observations merge you should make sure there is a good reason why.
>         */
.         sort date

.         order _merge date

.         br if _merge != 3

.         /*
>         By looking at the data we can see that the master data set begins in 1948, while the using data set begi
> ns
>                 in 1947. This explains our unmerged observations. In this case the unmerged observations were
>                 not a problem, but a merge is a common place for bugs to show themselves so it is especially
>                 important to check that the merge is working as you believe it should. A good way of doing this
>                 is the ASSERT command, which I will cover later.
>         */
. 
.         /* Now suppose we want to add GDP data to our data set. GDP, however, is measured at quarterly
>                 frequencies. If we tried to merge 1:1 we would get an error. There are two possible solutions
>                 to this issue. First, we could simply merge each quarter's GDP to all three months within that
>                 quarter. We do this with a many-to-on merge. Alternatively, we might transform our labor force
>                 and inflation data set to quarterly frequencies. We would accomplish this using collapse*/
. 
.         preserve

. 
.         /* Below I employ a many-to-one merge. This means that the merge variable does not uniquely identify
>                 observations in the master data set (data set in memory) but does uniquely identify observations
>                 in the using dataset. First we must create the merge variable, quarter, since we are merging at
>                 quarterly frequency but our existing date variable is measured at monthly frequency. (quarter
>                 already exists in the GDP data set we are merging with) We also must drop the _merge variable
>                 created by the previous merge or else we will get an error when this merge tries to create it */
.         drop _merge

.         gen quarter = qofd(dofm(date))

.         merge m:1 quarter using `directory'data/gdp.dta
quarter was float now double

    Result                           # of obs.
    -----------------------------------------
    not matched                             1
        from master                         1  (_merge==1)
        from using                          0  (_merge==2)

    matched                               795  (_merge==3)
    -----------------------------------------

.         tab _merge

                 _merge |      Freq.     Percent        Cum.
------------------------+-----------------------------------
        master only (1) |          1        0.13        0.13
            matched (3) |        795       99.87      100.00
------------------------+-----------------------------------
                  Total |        796      100.00

.         drop _merge

. 
.         /* Note:
>                 --- one-to-many (1:m) merges are analagous to many-to-one, however the merge variable uniquely
>                 identifies observations in the master rather than using data set.
>                 --- The merge variable could actually be a set of variables which together uniquely identify
>                 observations. For eaxample, instead of a single date variable we might have had year and month.
>         */
. 
.         restore

. 
.         /* Now, instead of adding GDP to each month, we will calculate quarterly averages of the unemployment
>                 rate and inflation rate and merge this 1:1 with GDP. */
.         gen quarter = qofd(dofm(date))

.         collapse (mean) u cpi, by(quarter)

.         merge 1:1 quarter using `directory'data/gdp.dta
quarter was float now double

    Result                           # of obs.
    -----------------------------------------
    not matched                             1
        from master                         1  (_merge==1)
        from using                          0  (_merge==2)

    matched                               265  (_merge==3)
    -----------------------------------------

.         tab _merge

                 _merge |      Freq.     Percent        Cum.
------------------------+-----------------------------------
        master only (1) |          1        0.38        0.38
            matched (3) |        265       99.62      100.00
------------------------+-----------------------------------
                  Total |        266      100.00

.         drop _merge

. 
.         /*
>         M:M merges also exist in Stata but you should never use them. For details (and proof that Stata Corp
>                has a sense of humor, see the documentation by typing ``help merge''.  If you think you want to
>                 perform a M:M merge, you may actually want a ``joinby''.
>         */
. 
. 
. /* Generating new and altering existing variables */
. 
.         use `directory'data/basic_labor_force.dta, clear

. 
.         /* It is simple to create new variables using the "generate" command (usually abbreviated "gen") or
>                 alter existing variables using the "replace" command.
>         */
. 
.         /* Let's create a new variable for the size of the labor force, equal to all of those employed or
>                 unemployed, and the employment-population ratio */
.         gen LF = E+U

.         gen epr = E/(E+U+N)

. 
.         /* We can round our existing employment-population ratio variable, epr to the nearest integer */
.         replace epr = round(epr)
(784 real changes made)

.         tab epr

        epr |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |        784      100.00      100.00
------------+-----------------------------------
      Total |        784      100.00

. 
.         /* The generate and replace commands are often used in conjunction with "if" commands. For example,
>                 we could create a dummy variable equal to 1 if the year is 2008 and 0 otherwise */
.         gen y2009       = 1 if year==2009
(772 missing values generated)

.         replace y2009   = 0 if year!= 2009
(772 real changes made)

. 
.         /* We could also generate the same binary variable without the if statement in this case */
.         gen y2009_alt = year==2009

.         tab y2009 y2009_alt

           |       y2009_alt
     y2009 |         0          1 |     Total
-----------+----------------------+----------
         0 |       772          0 |       772 
         1 |         0         12 |        12 
-----------+----------------------+----------
     Total |       772         12 |       784 


.         
.         /* Stata's *egen* command, for +e+xtensions to +gen+erate, is a powerful tool that
>                 can handle a number of additional functions. In Stata it is very rare that you
>                 will want to loop over observations of the data; if you find yourself wanting to
>                 loop over observations there is a good chance you should be using egen.
>                 In particular, it operates well on subgroups of data using the _by_ option
>                 Here, we use the mean function to get the annual mean unemployment rate 
>         */
.         bysort date: egen u_annual = mean(u)

. 
.         // Check on the basic stats of all variables (mean, stdev, min/max, etc)
.         summarize

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
           E |       784    99490.64    29832.24      57172     146595
           N |       784    60509.19    11969.32      42035      89967
           u |       784    5.813776    1.669649        2.5       10.8
           U |       784    6354.485    3041.249       1596      15382
        date |       784       247.5    226.4656       -144        639
-------------+--------------------------------------------------------
        year |       784    1980.168     18.8729       1948       2013
          LF |       784    105845.1    32228.57      59972     155654
         epr |       784           1           0          1          1
       y2009 |       784    .0153061    .1228458          0          1
   y2009_alt |       784    .0153061    .1228458          0          1
-------------+--------------------------------------------------------
    u_annual |       784    5.813776    1.669649        2.5       10.8

.         // Check detailed stats for u with the _detail_ option
.         su u, detail

                   Unemployment Rate, SA %
-------------------------------------------------------------
      Percentiles      Smallest
 1%          2.7            2.5
 5%          3.4            2.5
10%          3.8            2.6       Obs                 784
25%          4.6            2.6       Sum of Wgt.         784

50%          5.6                      Mean           5.813776
                        Largest       Std. Dev.      1.669649
75%          6.9           10.4
90%          8.1           10.4       Variance       2.787728
95%          9.1           10.8       Skewness       .5843024
99%         10.1           10.8       Kurtosis       2.998811

. 
. /* Labeling */
.         /* In order to keep things neat for other users (including future you), it is always a good idea to
>                 use labels. Stata allows you to affix labels to variables or to specific numeric observations
>                 of a variable. */
. 
.         gen month = month(dofm(date))

. 
.         // Adding informative variable labels to several variables 
.         label variable u "Unemployment Rate"

.         label variable E "Number Employed"

.         label variable U "Number Unemployed"

.         label variable N "Number Not in Labor Force"

. 
.         // Using value labels to label months
.         label define month_labels 1 "January" 2 "February" 3 "March" 4 "April" 5 "May" 6 "June"

.         label define month_labels 7 "July" 8 "August" 9 "September" 10 "October" 11 "November" 12 "December", ad
> d

.         label values month month_labels

. 
.         tab month

      month |      Freq.     Percent        Cum.
------------+-----------------------------------
    January |         66        8.42        8.42
   February |         66        8.42       16.84
      March |         66        8.42       25.26
      April |         66        8.42       33.67
        May |         65        8.29       41.96
       June |         65        8.29       50.26
       July |         65        8.29       58.55
     August |         65        8.29       66.84
  September |         65        8.29       75.13
    October |         65        8.29       83.42
   November |         65        8.29       91.71
   December |         65        8.29      100.00
------------+-----------------------------------
      Total |        784      100.00

.         br

. 
.         /* We can also attach notes to the variables or to the dataset itself for later reference, if desired
>                 Here we define a dataset note */
.         note : "Data source: BLS"

. 
.         // We can drop labels as well. For more details see "help label"
.         label drop month_labels

. 
. /* Some basic time series stuff */
. 
.         /* Suppose you want to create a lag of a variable. The most simple way to do this is to sort your data
>                 by date and reference the previous observation of the variable. This is poor Stata programming
>                 practice, however, for several reasons. You don't know whether or not date uniquely 
>                 identifies your data; you may have missing dates; you have to remember to sort the data.*/
.         sort date

.         gen u_lag = u[_n-1]
(1 missing value generated)

. 
.         /* For the reasons listed above it is better to -tsset- your data and then use time series operators to
>                 generate new variables. -tsset- declares one of your variables to be the time variable and
>                 ensures that it uniquely identifies the data. Once your data have been -tsset- you can use
>                 Stata's time series operators (for details type "help tsvarlist"). */
.         drop u_lag

. 
.         tsset date
        time variable:  date, 1948m1 to 2013m4
                delta:  1 month

.         gen u_lag = L.u         /* 1-period lag of u */
(1 missing value generated)

.         gen u_lag2 = L2.u       /* 2-period lag of u */
(2 missing values generated)

.         gen u_lead = F.u        /* 1-period lead of u */ 
(1 missing value generated)

.         gen u_diff = D.u        /* First difference of u */
(1 missing value generated)

. 
.         /* It is easy to smooth variables using the -tssmooth- command. The -tssmooth- command requires
>                 that your data has been -tsset-. Below I smooth the unemployment rate using a 12-month
>                 trailing moving average */
.         tssmooth ma u_ma = u, window(11,1,0)
The smoother applied was
     (1/12)*[x(t-11) + x(t-10) + x(t-9) + x(t-8) + x(t-7) + x(t-6) + x(t-5) + x(t-4) + x(t-3) + x(t-2) +
     x(t-1) + ...; x(t)= u

.         tsline u u_ma

. 
. /* Basic panel data stuff*/
. 
.         /* Stata's -xtset- command is its panel data analogoue to -tsset-. With -xtset- the use specifies
>                 both a timevar and a panelvar */
. 
.         sysuse xtline1, clear

. 
.         xtset person day
       panel variable:  person (strongly balanced)
        time variable:  day, 01jan2002 to 31dec2002
                delta:  1 day

.         gen lag_calories = L.calories
(3 missing values generated)

. 
.         /* This data set is in what's known as "long form," which means that there is one observation per
>                 person per day. Alternatively, we could store it in "wide form", meaning one observation
>                 per day and separate variables for each person. This might come in handy if we wanted to
>                 calculate the correlation between different people's calorie consumption or plot the series
>                 on the same graph. For this we use the -reshape- command. */
. 
.         drop lag_calories

.   
.         reshape wide calories, i(day) j(person)
(note: j = 1 2 3)

Data                               long   ->   wide
-----------------------------------------------------------------------------
Number of obs.                     1095   ->     365
Number of variables                   3   ->       4
j variable (3 values)            person   ->   (dropped)
xij variables:
                               calories   ->   calories1 calories2 calories3
-----------------------------------------------------------------------------

. 
.         label variable calories1 "Tess"

.         label variable calories2 "Sam"

.         label variable calories3 "Arnold"

. 
.         corr calories1 calories2 calories3
(obs=365)

             | calori~1 calori~2 calori~3
-------------+---------------------------
   calories1 |   1.0000
   calories2 |   0.7288   1.0000
   calories3 |   0.7774   0.9038   1.0000


.         tsline calories*

. 
. 
. 
. 
. /* RESHAPE */
. 
.         
. 
. log close `filename'
      name:  training
       log:  /home04/UserID/trainings/stata/logs/training_20130708181809.log
  log type:  text
 closed on:   8 Jul 2013, 18:18:15
------------------------------------------------------------------------------------------------------------------
